#ifndef PREFETCHER_HEADER
#define PREFETCHER_HEADER


/***************************************************************************
 *            koptprefetcher.h
 *
 *  Mon Oct 28 12:46:45 2002
 *  Copyright  2002  Roman Dementiev
 *  dementiev@mpi-sb.mpg.de
 ****************************************************************************/

#include <vector>
#include <queue>



struct set_switch_handler: public generic_completion_handler, public onoff_switch
{
	void operator() (request * req) { on(); }
};


template <typename run_type,
					typename block_type,
					typename run_cursor,
					typename run_cursor2,
					typename trigger_entry>
class prefetcher_writer
{
	prefetcher_writer ()
	{
	};
	
protected:	
	run_type *seq;
	int * prefetch_seq;
	run_type *out;
	unsigned nextread;
	unsigned nextconsume;
	unsigned nextwrite;
	const int nreadblocks;
	const int nwriteblocks;
	block_type *read_buffers;
	block_type *write_buffers;
	int *write_bids;	// bids (pos in out) of blocks in write_buffers
	request **read_reqs;
	request **write_reqs;
	const unsigned writebatchsize;

	std::vector<int> free_write_blocks;	// contains free write blocks
	std::vector<int> busy_write_blocks;	// blocks that are in writing, notice that if block is not in free_
																			// an not in busy then block is not yet filled

	set_switch_handler * completed;
	int * pref_buffer;

	struct batch_entry
	{
		off_t offset;
		int ibuffer;
		batch_entry (off_t o, int b):offset (o), ibuffer (b) { };
	};
	struct batch_entry_cmp
	{
		bool operator () (const batch_entry & a,
				  const batch_entry & b) const
		{
			return (a.offset > b.offset);
		};
	};

	typedef std::priority_queue<batch_entry,std::vector<batch_entry>,batch_entry_cmp> batch_type;

	batch_type batch_write_blocks;	// sorted sequence of blocks to write


public:
	prefetcher_writer(
			run_type * s, 
			int * p,
			run_type * o, 
			int nruns, 
			int prefetch_buf_size,
			int write_buf_size, 
			int write_batch_size
			):
		seq(s),
		prefetch_seq(p),
		out(o), 
		nextread (nruns + prefetch_buf_size),
		nextconsume(nruns),
		nextwrite(0),
		nreadblocks (nextread),
		nwriteblocks ((write_buf_size > 2) ? write_buf_size : 2),
		writebatchsize (write_batch_size ? write_batch_size : 1)
	{
		int i;
		read_buffers = new block_type[nreadblocks];
		read_reqs = new request *[nreadblocks];
		pref_buffer = new int [seq->size()];
		
		int * p1 = pref_buffer, * p1end = pref_buffer + seq->size();
		while(p1<p1end) *(p1++) = -1;

		completed = new set_switch_handler[seq->size()];
		
		for (i = 0; i < nreadblocks; i++)
		{
			assert( prefetch_seq[i] <seq->size() && prefetch_seq[i] >= 0 );
			read_buffers[i].read (
										(*seq)[prefetch_seq[i]].bid,
										read_reqs[i],
										*(completed + prefetch_seq[i]) );
			pref_buffer[prefetch_seq[i]] = i;
		};


		write_buffers = new block_type[nwriteblocks];
		write_reqs = new request *[nwriteblocks];
		write_bids = new int[nwriteblocks];

		for (i = 0; i < nwriteblocks; i++)
			free_write_blocks.push_back (i);

		START_COUNT_WAIT_TIME
		for(i = 0 ; i< nruns;i++)
		{
			assert(pref_buffer[i] >= 0);
			completed[i].wait_for_on(); // must not deadlock !!!
			delete read_reqs[pref_buffer[i]];
		};
		END_COUNT_WAIT_TIME
		// Uuuh
	};
	block_type *r_block (int i)
	{
		return (read_buffers + pref_buffer[i]);
	};
	block_type *w_block (int i)
	{
		return (write_buffers + i);
	};

	int wait_read_completion (int iblock)
	{
		START_COUNT_WAIT_TIME
		completed[iblock].wait_for_on();
		END_COUNT_WAIT_TIME
		int ibuffer = pref_buffer[iblock];
		assert(ibuffer >= 0 && ibuffer < nreadblocks );
		delete read_reqs[ibuffer];
		return ibuffer;
	};

	bool block_consumed (run_cursor & cursor)	// return false if seq emptied
	{
		if (nextread < seq->size ())
		{
			int ibuffer = cursor.buffer - read_buffers;
			assert(ibuffer >=0 && ibuffer <nreadblocks);
			int next_2_prefetch = prefetch_seq[nextread++];
			assert( next_2_prefetch < seq->size() && next_2_prefetch >= 0 );
			assert( !completed[next_2_prefetch].is_on() );
			pref_buffer[next_2_prefetch] = ibuffer;
			read_buffers[ibuffer].read(
								(*seq)[next_2_prefetch].bid,
						    read_reqs[ibuffer],
								set_switch,
								(void *)(completed+next_2_prefetch)
							);
		}

		if (nextconsume >= seq->size())
			return false;

		cursor.buffer = read_buffers + wait_read_completion(nextconsume++);
		cursor.pos = 0;


		return true;
	}

	void block_consumed (run_cursor2 & cursor)	// return false if seq emptied
	{
		if (nextread < seq->size ())
		{
			int ibuffer = cursor.buffer - read_buffers;
			assert(ibuffer >=0 && ibuffer <nreadblocks);
			int next_2_prefetch = prefetch_seq[nextread++];
			
			assert(next_2_prefetch <seq->size() && next_2_prefetch >= 0 );
			assert(!completed[next_2_prefetch].is_on() );
			
			pref_buffer[next_2_prefetch] = ibuffer;
			read_buffers[ibuffer].read(
								(*seq)[next_2_prefetch].bid,
						    read_reqs[ibuffer],
								*(completed+next_2_prefetch)
							);
		}

		if (nextconsume < seq->size())
		{
			cursor.buffer = read_buffers + wait_read_completion(nextconsume++);
			cursor.pos = 0;
		}
	}

	bool block_consumed (block_type * &buffer)	// return false if seq emptied
	{
		if (nextread < seq->size ())
		{
			int ibuffer = buffer - read_buffers;
			assert(ibuffer >=0 && ibuffer <nreadblocks);
			int next_2_prefetch = prefetch_seq[nextread++];
			
			assert(next_2_prefetch <seq->size() && next_2_prefetch >= 0 );
			assert( !completed[next_2_prefetch].is_on() );
			
			pref_buffer[next_2_prefetch] = ibuffer;
			read_buffers[ibuffer].read(
								(*seq)[next_2_prefetch].bid,
						    read_reqs[ibuffer],
								*(completed+next_2_prefetch)
							);
		}

		if (nextconsume >= seq->size())
			return false;

		buffer = read_buffers + wait_read_completion(nextconsume++);

		return true;
	}

	int get_free_write_block ()
	{
		int ibuffer;
		for (std::vector < int >::iterator it =
		     busy_write_blocks.begin ();
		     it != busy_write_blocks.end (); it++)
		{
			if (write_reqs[ibuffer = (*it)]->poll ())
			{
				delete write_reqs[ibuffer];
				busy_write_blocks.erase (it);
				free_write_blocks.push_back (ibuffer);

				break;
			}
		}
		if (UNLIKELY (free_write_blocks.empty ()))
		{
			//      STXXL_MSG( "Out of output buffers, waiting (busy:"<<busy_write_blocks.size()<<" all:"<< nwriteblocks <<")" )

			int size = busy_write_blocks.size ();
			request **reqs = new request *[size];
			int i = 0;
			for (; i < size; i++)
			{
				reqs[i] = write_reqs[busy_write_blocks[i]];
			}
			int completed = mc::wait_any (reqs, size);
			//      STXXL_MSG( "Out of output buffers, block finished" )
			//      assert(completed >= 0 && completed < size );
			int completed_global = busy_write_blocks[completed];
			delete[]reqs;
			busy_write_blocks.erase (busy_write_blocks.begin () +
						 completed);
			delete write_reqs[completed_global];

			write_bids[completed_global] = nextwrite++;

			return completed_global;
		}
		ibuffer = free_write_blocks.back ();
		free_write_blocks.pop_back ();

		write_bids[ibuffer] = nextwrite++;

		//    STXXL_MSG("Block "<<ibuffer << " given")

		return ibuffer;
	}
	

	int block_filled (int filled_block)	// writes filled_block and returns new block 
	{
		//    int new_block = get_free_write_block();
		//    STXXL_MSG("Block filled, write batch size: "<< batch_write_blocks.size())

		if (batch_write_blocks.size () >= writebatchsize)
		{
			// flush batch
			//      STXXL_MSG("Flushing write blocks");
			while (!batch_write_blocks.empty ())
			{
				int ibuffer = batch_write_blocks.top ().ibuffer;
				batch_write_blocks.pop ();

				trigger_entry & next_trigger = (*out)[write_bids[ibuffer]];
				next_trigger.key = write_buffers[ibuffer].elem->key();
				write_buffers[ibuffer].write (next_trigger.
							      bid,
							      write_reqs
							      [ibuffer]);

				busy_write_blocks.push_back (ibuffer);
			}

		}

		//    STXXL_MSG("Adding write request to batch")
		batch_write_blocks.push(batch_entry((*out)[write_bids[filled_block]].bid.offset,filled_block));


		return get_free_write_block ();
	}


	~prefetcher_writer ()
	{
		int ibuffer;
		delete [] completed;
		delete [] pref_buffer;
		
		while (!batch_write_blocks.empty ())
		{
			ibuffer = batch_write_blocks.top ().ibuffer;
			batch_write_blocks.pop ();

			trigger_entry & next_trigger =
				(*out)[write_bids[ibuffer]];
			next_trigger.key = write_buffers[ibuffer].elem->key();
			write_buffers[ibuffer].write (next_trigger.bid,
						      write_reqs[ibuffer]);

			busy_write_blocks.push_back (ibuffer);
		}
		for (std::vector < int >::const_iterator it =
		     busy_write_blocks.begin ();
		     it != busy_write_blocks.end (); it++)
		{
			ibuffer = *it;
			write_reqs[ibuffer]->wait ();
			delete write_reqs[ibuffer];
		}

		delete[]read_buffers;
		delete[]write_buffers;
		delete[]read_reqs;
		delete[]write_reqs;
		delete[]write_bids;

	}
};

#endif
